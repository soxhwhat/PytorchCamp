{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_stwzbAVVHMt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfxbdP6eVQSN",
        "outputId": "b89bf5c3-b5cc-4f19-9c1c-6d196759e15a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/SPPNet')"
      ],
      "metadata": {
        "id": "LBK1lqShVXA1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/yifanjiang97/sppnet-pytorch.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4j5uGAPVhOU",
        "outputId": "4e67b0cb-2377-4143-973f-82e28a55859b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'sppnet-pytorch'...\n",
            "remote: Enumerating objects: 31, done.\u001b[K\n",
            "remote: Total 31 (delta 0), reused 0 (delta 0), pack-reused 31\u001b[K\n",
            "Unpacking objects: 100% (31/31), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "spp_layer\n"
      ],
      "metadata": {
        "id": "2UMb31dQWHhq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "def spatial_pyramid_pool(self, previous_conv, num_sample, previous_conv_size, out_pool_size):\n",
        "  '''\n",
        "  previous_conv: a tensor vector of previous convolution layer\n",
        "  num_sample: an int number of image in the batch\n",
        "  previous_conv_size: an int vector [height, width] of the matrix features size of previous convolution layer\n",
        "  out_pool_size: a int vector of expected output size of max pooling layer\n",
        "  \n",
        "  returns: a tensor vector with shape [1 x n] is the concentration of multi-level pooling\n",
        "  '''\n",
        "\n",
        "  for i in range(len(out_pool_size)):\n",
        "    h_wid = int(math.ceil(previous_conv_size[0] / out_pool_size[i]))\n",
        "    w_wid = int(math.ceil(previous_conv_size[1] / out_pool_size[1]))\n",
        "    # 反卷积计算\n",
        "    h_pad = (h_wid * out_pool_size[i] - previous_conv_size[0] + 1) / 2\n",
        "    w_pad = (w_wid * out_pool_size[i] - previous_conv_size[1] + 1) / 2\n",
        "    maxpool = nn.MaxPool2d((h_wid, w_wid), stride= (h_wid, w_wid), padding = (h_pad, w_pad))\n",
        "    x = maxpool(previous_conv)\n",
        "    if(i == 0):\n",
        "      spp = x.view(num_sample, -1)\n",
        "    else:\n",
        "      spp = torch.cat((spp, x.view(num_sample, -1)), 1)\n",
        "    \n",
        "  return spp"
      ],
      "metadata": {
        "id": "lD9aI4saVwtM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "cnn_with_spp\n"
      ],
      "metadata": {
        "id": "sjGCS6c_iTLF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import init\n",
        "import functools\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import\n",
        "\n",
        "class SSP_NET(nn.Module):\n",
        "  '''\n",
        "  A CNN model which adds spp layer so that we can input multi-size tensor\n",
        "  '''\n",
        "\n",
        "  def __init__(self, opt, input_nc, ndf=64, gpu_ids=[]):\n",
        "    super(SPP_NET, self).__init__()\n",
        "    super.gpu_ids = gpu_ids\n",
        "    self.output_num = [4,2,1]\n",
        "\n",
        "    self.conv1 = nn.Conv2d(input_nc, ndf, 4, 2, 1, bias=False)\n",
        "\n",
        "    self.conv2 = nn.Conv2d(ndf, ndf * 2, 4, 1, 1, bias=False)\n",
        "    self.BN1 = nn.BatchNorm2d(ndf * 2)\n",
        "\n",
        "    self.conv3 = nn.Conv2d(ndf * 2, ndf * 4, 4, 1, 1, bias=False)\n",
        "    self.BN2 = nn.BatchNorm2d(ndf * 4)\n",
        "\n",
        "    self.conv4 = nn.Conv2d(ndf * 4, ndf * 8, 4, 1, 1, bias=False)\n",
        "    self.BN3 = nn.BatchNorm2d(ndf * 8)\n",
        "\n",
        "    self.conv5 = nn.Conv2d(ndf * 8, 64, 4, 1, 0, bias=False)\n",
        "    self.fc1 = nn.Linear(10752, 4096)\n",
        "    self.fc2 = nn.Linear(4096, 1000)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.LReLU1(x)\n",
        "\n",
        "    x = self.conv2(x)\n",
        "    x = F.leaky_relu(self.BN1(x))\n",
        "\n",
        "    x = self.conv3(x)\n",
        "    # x = F.leaky_relu(self.BN3(x))\n",
        "    # x = self.conv5(x)\n",
        "    spp = spatial_pyramid_pool(x, 1, [int(x.size(2)), int(x.size(3))], self.output_num)\n",
        "    # print(spp.size())\n",
        "    fc1 = self.fc1(spp)\n",
        "    fc2 = self.fc2(fc1)\n",
        "    s = nn.Sigmoid()\n",
        "    output = s(fc2)\n",
        "    return output"
      ],
      "metadata": {
        "id": "ttVxPmWpj3jR"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}